# üöÄ MineWise ML API - Deployment Guide

## Overview

**MineWise ML API** adalah REST API berbasis FastAPI untuk prediksi operasional tambang menggunakan 5 machine learning models dengan feature engineering pipeline yang telah dioptimasi.

**API Version**: 1.0  
**Framework**: FastAPI + Uvicorn  
**Python Version**: 3.9+  
**Status**: Production Ready ‚úÖ

---

## üìã Table of Contents

1. [System Requirements](#system-requirements)
2. [Installation](#installation)
3. [Configuration](#configuration)
4. [Running the API](#running-the-api)
5. [API Endpoints](#api-endpoints)
6. [Feature Engineering](#feature-engineering)
7. [Testing & Validation](#testing--validation)
8. [Production Deployment](#production-deployment)
9. [Monitoring & Logging](#monitoring--logging)
10. [Troubleshooting](#troubleshooting)

---

## System Requirements

### Minimum Requirements

- **OS**: Windows 10/11, Linux (Ubuntu 20.04+), macOS 11+
- **CPU**: 4 cores, 2.5 GHz
- **RAM**: 8 GB
- **Storage**: 5 GB free space
- **Python**: 3.9 or 3.10 (recommended)

### Recommended for Production

- **CPU**: 8+ cores, 3.0+ GHz
- **RAM**: 16 GB
- **Storage**: 20 GB SSD
- **Network**: 1 Gbps
- **Load Balancer**: Nginx or HAProxy

---

## Installation

### Step 1: Clone Repository

```bash
git clone https://github.com/Akmalalfatah/minewise.git
cd minewise/capstone-project/minewise_ml
```

### Step 2: Create Virtual Environment

**Windows (PowerShell)**:
```powershell
python -m venv venv
.\venv\Scripts\Activate.ps1
```

**Linux/macOS**:
```bash
python3 -m venv venv
source venv/bin/activate
```

### Step 3: Install Dependencies

```bash
# Core dependencies
pip install --upgrade pip
pip install -r requirements.txt

# Additional packages for production
pip install gunicorn  # Linux/macOS only
pip install python-multipart
pip install prometheus-client  # For monitoring
```

### Step 4: Verify Installation

```bash
python -c "import fastapi, uvicorn, pandas, numpy, joblib; print('‚úÖ All dependencies installed')"
```

---

## Configuration

### Environment Variables

Create `.env` file in project root:

```env
# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
API_WORKERS=4
API_RELOAD=false

# Model Paths
MODELS_DIR=models
FEATURE_STORE_DIR=data/feature_store

# Logging
LOG_LEVEL=INFO
LOG_FILE=logs/api.log

# CORS (if needed)
ALLOW_ORIGINS=["http://localhost:3000", "https://minewise.com"]

# Performance
MAX_REQUEST_SIZE=10MB
TIMEOUT_SECONDS=30
```

### Model Files Required

Ensure these model files exist in `models/` directory:

```
models/
‚îú‚îÄ‚îÄ road_speed_model.pkl            (‚úÖ Required)
‚îú‚îÄ‚îÄ cycle_time_optimized.pkl        (‚úÖ Required)
‚îú‚îÄ‚îÄ road_risk_model.pkl             (‚úÖ Required)
‚îú‚îÄ‚îÄ equipment_failure_model.pkl     (‚úÖ Required)
‚îú‚îÄ‚îÄ port_operability_model.pkl      (‚úÖ Required)
‚îú‚îÄ‚îÄ road_speed_metadata.json        (Optional)
‚îú‚îÄ‚îÄ cycle_time_metadata.json        (Optional)
‚îú‚îÄ‚îÄ road_risk_metadata.json         (‚ö†Ô∏è Contains threshold info)
‚îú‚îÄ‚îÄ equipment_failure_metadata.json (Optional)
‚îî‚îÄ‚îÄ port_operability_metadata.json  (Optional)
```

**Check model files**:
```bash
ls -lh models/*.pkl
```

---

## Running the API

### Development Mode (Local Testing)

**Windows PowerShell**:
```powershell
# Simple start
python -m uvicorn src.api.main:app --reload --host 0.0.0.0 --port 8000

# With specific Python interpreter
C:/Users/I5/AppData/Local/Programs/Python/Python310/python.exe -m uvicorn src.api.main:app --host 0.0.0.0 --port 8000

# In new window (PowerShell)
Start-Process powershell -ArgumentList "-NoExit", "-Command", "cd '$PWD'; python -m uvicorn src.api.main:app --host 0.0.0.0 --port 8000" -WindowStyle Normal
```

**Linux/macOS**:
```bash
# Development with auto-reload
uvicorn src.api.main:app --reload --host 0.0.0.0 --port 8000

# Production-like (no reload)
uvicorn src.api.main:app --host 0.0.0.0 --port 8000 --workers 4
```

### Production Mode

**Using Gunicorn (Linux/macOS)**:
```bash
gunicorn src.api.main:app \
  --workers 4 \
  --worker-class uvicorn.workers.UvicornWorker \
  --bind 0.0.0.0:8000 \
  --timeout 60 \
  --access-logfile logs/access.log \
  --error-logfile logs/error.log \
  --log-level info
```

**Using Uvicorn (Windows)**:
```powershell
uvicorn src.api.main:app --host 0.0.0.0 --port 8000 --workers 4 --log-level info
```

### Docker Deployment (Optional)

**Dockerfile**:
```dockerfile
FROM python:3.10-slim

WORKDIR /app

# Install dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application
COPY . .

# Expose port
EXPOSE 8000

# Run API
CMD ["uvicorn", "src.api.main:app", "--host", "0.0.0.0", "--port", "8000", "--workers", "4"]
```

**Build and run**:
```bash
docker build -t minewise-api .
docker run -d -p 8000:8000 --name minewise minewise-api
```

### Health Check

After starting, verify API is running:

```bash
# Check health endpoint
curl http://localhost:8000/health

# Expected response:
# {"status":"healthy","models_loaded":5,"timestamp":"2025-12-10T..."}
```

---

## API Endpoints

### Base URL

- **Development**: `http://localhost:8000`
- **Production**: `https://api.minewise.com` (configure as needed)

### Interactive Documentation

- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

### Endpoints Overview

| Endpoint | Method | Purpose | Input Fields | Response |
|----------|--------|---------|--------------|----------|
| `/health` | GET | Health check | None | Status, models loaded |
| `/predict/road-speed` | POST | Road speed prediction | 9 fields (road, weather) | Speed (km/h) |
| `/predict/cycle-time` | POST | Cycle time prediction | 6 fields (distance, speed) | Time (minutes) |
| `/predict/road-risk` | POST | Road risk classification | 4 fields (road condition) | Risk class (BAIK/WASPADA/TERBATAS) |
| `/predict/equipment-failure` | POST | Equipment failure prediction | 4 fields (equipment info) | Status (Operational/Breakdown Risk) |
| `/predict/port-operability` | POST | Port operability prediction | 4 fields (weather, vessel) | Operability class |
| `/predict/batch` | POST | Batch predictions | Multiple model inputs | All predictions |

---

## Detailed Endpoint Documentation

### 1. Road Speed Prediction

**Endpoint**: `POST /predict/road-speed`

**Purpose**: Predict optimal hauling speed based on road and weather conditions.

**Request Schema**:
```json
{
  "jenis_jalan": "UTAMA",          // "UTAMA", "CABANG", "PENGHUBUNG"
  "kondisi_permukaan": "KERING",   // "KERING", "BASAH", "BERLUMPUR"
  "curah_hujan_mm": 0.5,           // 0-100 mm
  "suhu_celcius": 32.0,            // 15-45 ¬∞C
  "kecepatan_angin_ms": 3.0,       // 0-20 m/s
  "elevasi_mdpl": 150.0,           // 0-500 mdpl
  "kemiringan_persen": 2.0,        // 0-30 %
  "beban_muatan_ton": 40.0,        // 0-120 ton
  "jam_operasi": 10                // 0-23 hour
}
```

**Response**:
```json
{
  "success": true,
  "prediction": 33.51,             // km/h
  "confidence": 0.92,              // 0-1
  "recommendations": [
    "‚úÖ Optimal speed for current conditions",
    "‚ö†Ô∏è Reduce speed in wet conditions"
  ],
  "timestamp": "2025-12-10T10:30:00"
}
```

**cURL Example**:
```bash
curl -X POST "http://localhost:8000/predict/road-speed" \
  -H "Content-Type: application/json" \
  -d '{
    "jenis_jalan": "UTAMA",
    "kondisi_permukaan": "KERING",
    "curah_hujan_mm": 0.5,
    "suhu_celcius": 32.0,
    "kecepatan_angin_ms": 3.0,
    "elevasi_mdpl": 150.0,
    "kemiringan_persen": 2.0,
    "beban_muatan_ton": 40.0,
    "jam_operasi": 10
  }'
```

**Python Example**:
```python
import requests

response = requests.post(
    "http://localhost:8000/predict/road-speed",
    json={
        "jenis_jalan": "UTAMA",
        "kondisi_permukaan": "KERING",
        "curah_hujan_mm": 0.5,
        "suhu_celcius": 32.0,
        "kecepatan_angin_ms": 3.0,
        "elevasi_mdpl": 150.0,
        "kemiringan_persen": 2.0,
        "beban_muatan_ton": 40.0,
        "jam_operasi": 10
    }
)

result = response.json()
print(f"Predicted speed: {result['prediction']} km/h")
```

---

### 2. Cycle Time Prediction

**Endpoint**: `POST /predict/cycle-time`

**Purpose**: Predict hauling cycle time based on distance and conditions.

**Request Schema**:
```json
{
  "jarak_tempuh_km": 12.5,         // 0-50 km
  "kecepatan_prediksi_kmh": 25.0,  // 10-50 km/h (from road-speed)
  "curah_hujan_mm": 1.2,           // 0-100 mm
  "kondisi_jalan": "BAIK",         // "BAIK", "SEDANG", "BURUK"
  "beban_muatan_ton": 90.0,        // 0-120 ton
  "jumlah_stop": 2                 // 0-10 stops
}
```

**Response**:
```json
{
  "success": true,
  "prediction": 11.27,             // minutes
  "confidence": 0.88,
  "recommendations": [
    "‚è±Ô∏è Normal cycle time for route",
    "üö¶ Minimize stops to improve efficiency"
  ],
  "timestamp": "2025-12-10T10:35:00"
}
```

---

### 3. Road Risk Classification

**Endpoint**: `POST /predict/road-risk`

**Purpose**: Classify road safety level (CRITICAL for mining safety).

**Request Schema**:
```json
{
  "jenis_jalan": "CABANG",         // "UTAMA", "CABANG", "PENGHUBUNG"
  "kondisi_permukaan": "BERLUMPUR",// "KERING", "BASAH", "BERLUMPUR"
  "curah_hujan_mm": 70.0,          // 0-100 mm
  "kemiringan_persen": 25.0        // 0-30 %
}
```

**Response**:
```json
{
  "success": true,
  "prediction": "TERBATAS",        // "BAIK", "WASPADA", "TERBATAS"
  "confidence": 0.548,
  "recommendations": [
    "üö® DANGEROUS ROAD - Reduce speed to <20 km/h",
    "‚ö†Ô∏è High risk conditions - consider alternative route",
    "üåßÔ∏è Heavy rain impact - expect hazardous conditions"
  ],
  "timestamp": "2025-12-10T10:40:00"
}
```

**Risk Classes**:
- **BAIK** (Good): Normal operations, speed >30 km/h
- **WASPADA** (Caution): Reduce speed to 20-30 km/h
- **TERBATAS** (Dangerous): CRITICAL - Speed <20 km/h or avoid route

**‚ö†Ô∏è IMPORTANT**: Model recall for TERBATAS is 48% (improved from 13.3%). For critical safety:
- Threshold: TERBATAS probability >5% ‚Üí Flag as dangerous
- Always combine with manual inspection for critical routes
- See `docs/ROAD_RISK_RECALL_IMPROVEMENT_REPORT.md` for details

---

### 4. Equipment Failure Prediction

**Endpoint**: `POST /predict/equipment-failure`

**Purpose**: Predict equipment operational status or breakdown risk.

**Request Schema**:
```json
{
  "jenis_equipment": "Dump Truck", // "Excavator", "Dump Truck", "Loader", etc.
  "umur_tahun": 10.0,              // 0-20 years (accepts decimals)
  "jam_operasional_harian": 22.0,  // 0-24 hours/day
  "ritase_harian": 95.0            // 0-150 trips/day
}
```

**Response**:
```json
{
  "success": true,
  "prediction": "Breakdown Risk",  // "Operational" or "Breakdown Risk"
  "confidence": 0.995,
  "recommendations": [
    "‚ö†Ô∏è High breakdown risk - schedule immediate maintenance",
    "üîß Equipment age >8 years - consider replacement evaluation",
    "üìä Heavy usage pattern - increase inspection frequency"
  ],
  "timestamp": "2025-12-10T10:45:00"
}
```

**Note**: Feature engineering generates excellent discrimination (condition_score variation 0.51), but model predictions have high confidence (99.5-99.7%) due to training data characteristics. Classifications are correct but confidence values may not reflect true uncertainty.

---

### 5. Port Operability Prediction

**Endpoint**: `POST /predict/port-operability`

**Purpose**: Predict port operational status based on weather conditions.

**Request Schema**:
```json
{
  "tinggi_gelombang_m": 4.5,       // 0-8 meters
  "kecepatan_angin_kmh": 75.0,     // 0-120 km/h
  "tipe_kapal": "Container Ship",  // "Bulk Carrier", "Container Ship", etc.
  "kapasitas_muatan_ton": 110000   // 10000-200000 ton
}
```

**Response**:
```json
{
  "success": true,
  "prediction": "MODERATE",        // Operability class
  "confidence": 0.906,
  "recommendations": [
    "‚õàÔ∏è Storm conditions - expect delays",
    "üåä High waves (4.5m) - berth operations limited",
    "üí® Strong winds (75 km/h) - use caution"
  ],
  "timestamp": "2025-12-10T10:50:00"
}
```

**Note**: Model tends to predict MODERATE class due to training data bias. Confidence variation (90.6-99.2%) correctly reflects weather severity. Use confidence levels as risk indicators.

---

### 6. Batch Predictions

**Endpoint**: `POST /predict/batch`

**Purpose**: Get predictions from multiple models in one request.

**Request Schema**:
```json
{
  "road_speed": {
    "jenis_jalan": "UTAMA",
    "kondisi_permukaan": "KERING",
    ...
  },
  "cycle_time": {
    "jarak_tempuh_km": 12.5,
    ...
  },
  "equipment_failure": {
    "jenis_equipment": "Excavator",
    ...
  }
  // Include any combination of models
}
```

**Response**:
```json
{
  "success": true,
  "predictions": {
    "road_speed": 33.51,
    "cycle_time": 11.27,
    "equipment_failure": "Operational"
  },
  "timestamp": "2025-12-10T10:55:00"
}
```

---

## Feature Engineering

### Overview

**CRITICAL**: All API endpoints use **feature engineering pipeline** to transform simple business inputs (4-9 fields) into complex model features (38-44 fields).

**Architecture**:
```
API Input (Simple) ‚Üí FeatureEngineer ‚Üí Engineered Features (Complex) ‚Üí Model ‚Üí Prediction
    4-9 fields              ‚Üì              38-44 fields
                    Normalized factors
                    Health scores
                    Composite features
                    Temporal encoding
```

### Feature Engineering Success Metrics

| Model | Input Fields | Engineered Features | Condition Score Variation |
|-------|--------------|---------------------|---------------------------|
| Road Speed/Risk | 9 | 38 (infrastructure) | N/A (regression/classification) |
| Cycle Time | 6 | 38 (infrastructure) | N/A (regression) |
| Equipment Failure | 4 | 44 (fleet) | **0.51** (0.23 ‚Üí 0.74) ‚úÖ |
| Port Operability | 4 | 44 (fleet) | **0.61** (0.28 ‚Üí 0.89) ‚úÖ |

**Key Techniques**:
1. **Normalized Factors**: `age_factor = min(age/12, 1.0)` for consistent [0,1] scaling
2. **Weighted Combinations**: `risk = age√ó0.5 + usage√ó0.3 + trips√ó0.2`
3. **Discriminative Health Scores**: Lower floors (0.1-0.3) for wider ranges
4. **Composite Scores**: Prioritized by operational importance

**See**: `docs/FEATURE_ENGINEERING_IMPROVEMENT_REPORT.md` for complete technical details.

---

## Testing & Validation

### Automated Test Suite

**Comprehensive validation test** for all 5 models:

```bash
python test_complete_validation.py
```

**Expected output**:
```
üéØ FINAL VALIDATION - ALL 5 MODELS WITH FEATURE ENGINEERING
===========================================================================
1. ROAD SPEED PREDICTION
‚úÖ Optimal Dry Main Road       ‚Üí  33.51 km/h (conf: 92.0%)
‚úÖ Heavy Rain Muddy Branch     ‚Üí  27.06 km/h (conf: 92.0%)
üìä Variation: 6.45 km/h

2. EQUIPMENT FAILURE
‚úÖ New Excavator - Light Use   ‚Üí Operational (conf: 99.7%)
‚úÖ Old Dump Truck - Heavy Use  ‚Üí Breakdown Risk (conf: 99.5%)
üìä Confidence variation: 0.20%

... (all 5 models tested)

üéâ ALL 5 MODELS WORKING! Feature Engineering Pipeline Successful!
```

### Manual Testing

**Test individual endpoints**:

```bash
# Road Speed
curl -X POST "http://localhost:8000/predict/road-speed" \
  -H "Content-Type: application/json" \
  -d '{"jenis_jalan":"UTAMA","kondisi_permukaan":"KERING","curah_hujan_mm":0.5,"suhu_celcius":32.0,"kecepatan_angin_ms":3.0,"elevasi_mdpl":150.0,"kemiringan_persen":2.0,"beban_muatan_ton":40.0,"jam_operasi":10}'

# Equipment Failure
curl -X POST "http://localhost:8000/predict/equipment-failure" \
  -H "Content-Type: application/json" \
  -d '{"jenis_equipment":"Excavator","umur_tahun":1.5,"jam_operasional_harian":6.0,"ritase_harian":35.0}'
```

### Performance Benchmarks

**Expected performance** (tested on 4-core, 8GB RAM machine):

| Metric | Value | Status |
|--------|-------|--------|
| Average response time | <200ms | ‚úÖ Excellent |
| 95th percentile | <500ms | ‚úÖ Good |
| Max concurrent requests | 100+ | ‚úÖ Scalable |
| Memory usage | ~300MB | ‚úÖ Efficient |
| Model loading time | ~2-3s | ‚úÖ Acceptable |

---

## Production Deployment

### Pre-Deployment Checklist

- [ ] All model files present in `models/` directory
- [ ] Environment variables configured in `.env`
- [ ] Dependencies installed (`pip install -r requirements.txt`)
- [ ] Test suite passing (`python test_complete_validation.py`)
- [ ] Health check responding (`curl http://localhost:8000/health`)
- [ ] Logs directory created (`mkdir -p logs`)
- [ ] Firewall rules configured (allow port 8000 or custom port)
- [ ] SSL/TLS certificates ready (if using HTTPS)
- [ ] Monitoring setup (Prometheus, Grafana, etc.)
- [ ] Backup strategy for models and logs

### Deployment Options

#### Option 1: Systemd Service (Linux)

Create `/etc/systemd/system/minewise-api.service`:

```ini
[Unit]
Description=MineWise ML API
After=network.target

[Service]
Type=simple
User=minewise
WorkingDirectory=/opt/minewise_ml
Environment="PATH=/opt/minewise_ml/venv/bin"
ExecStart=/opt/minewise_ml/venv/bin/uvicorn src.api.main:app --host 0.0.0.0 --port 8000 --workers 4
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target
```

**Enable and start**:
```bash
sudo systemctl daemon-reload
sudo systemctl enable minewise-api
sudo systemctl start minewise-api
sudo systemctl status minewise-api
```

#### Option 2: Windows Service

Use `NSSM` (Non-Sucking Service Manager):

```powershell
# Download NSSM
# Install service
nssm install MineWiseAPI "C:\Python310\python.exe" "-m uvicorn src.api.main:app --host 0.0.0.0 --port 8000"
nssm set MineWiseAPI AppDirectory "C:\minewise_ml"
nssm start MineWiseAPI
```

#### Option 3: Docker Compose

**docker-compose.yml**:
```yaml
version: '3.8'

services:
  api:
    build: .
    container_name: minewise-api
    ports:
      - "8000:8000"
    environment:
      - LOG_LEVEL=INFO
    volumes:
      - ./models:/app/models:ro
      - ./logs:/app/logs
    restart: always
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
```

**Deploy**:
```bash
docker-compose up -d
docker-compose logs -f api
```

#### Option 4: Kubernetes (Advanced)

**deployment.yaml**:
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: minewise-api
spec:
  replicas: 3
  selector:
    matchLabels:
      app: minewise-api
  template:
    metadata:
      labels:
        app: minewise-api
    spec:
      containers:
      - name: api
        image: minewise-api:latest
        ports:
        - containerPort: 8000
        resources:
          requests:
            memory: "1Gi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "1000m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
```

### Reverse Proxy (Nginx)

**nginx.conf**:
```nginx
upstream minewise_api {
    server 127.0.0.1:8000;
    server 127.0.0.1:8001;  # If running multiple instances
}

server {
    listen 80;
    server_name api.minewise.com;

    location / {
        proxy_pass http://minewise_api;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # Timeouts
        proxy_connect_timeout 60s;
        proxy_send_timeout 60s;
        proxy_read_timeout 60s;
        
        # WebSocket support (if needed)
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
    }

    # HTTPS redirect (configure SSL separately)
    # listen 443 ssl;
    # ssl_certificate /etc/ssl/certs/minewise.crt;
    # ssl_certificate_key /etc/ssl/private/minewise.key;
}
```

### Load Balancing

For high traffic, run multiple API instances:

```bash
# Instance 1
uvicorn src.api.main:app --host 127.0.0.1 --port 8000 --workers 4

# Instance 2
uvicorn src.api.main:app --host 127.0.0.1 --port 8001 --workers 4

# Instance 3
uvicorn src.api.main:app --host 127.0.0.1 --port 8002 --workers 4
```

Configure Nginx upstream to balance across all instances.

---

## Monitoring & Logging

### Application Logs

**Log files**:
- `logs/api.log` - Main application logs
- `logs/access.log` - HTTP request logs
- `logs/error.log` - Error logs

**Log format**:
```
[2025-12-10 10:30:15] INFO - Road speed prediction: 33.51 km/h (confidence: 92%)
[2025-12-10 10:30:20] ERROR - Equipment failure prediction error: Model file not found
```

**Log rotation** (Linux - logrotate):

Create `/etc/logrotate.d/minewise-api`:
```
/opt/minewise_ml/logs/*.log {
    daily
    rotate 14
    compress
    delaycompress
    notifempty
    create 0640 minewise minewise
    sharedscripts
    postrotate
        systemctl reload minewise-api
    endscript
}
```

### Health Monitoring

**Endpoint**: `GET /health`

**Response**:
```json
{
  "status": "healthy",
  "models_loaded": 5,
  "models": {
    "road_speed": "loaded",
    "cycle_time": "loaded",
    "road_risk": "loaded",
    "equipment_failure": "loaded",
    "port_operability": "loaded"
  },
  "timestamp": "2025-12-10T10:30:00",
  "uptime_seconds": 3600
}
```

**Monitoring script** (cron every 5 minutes):
```bash
#!/bin/bash
STATUS=$(curl -s http://localhost:8000/health | jq -r '.status')
if [ "$STATUS" != "healthy" ]; then
    echo "API unhealthy!" | mail -s "MineWise API Alert" admin@minewise.com
    systemctl restart minewise-api
fi
```

### Prometheus Metrics

Add Prometheus middleware to FastAPI:

```python
from prometheus_client import Counter, Histogram, make_asgi_app

# Metrics
request_count = Counter('api_requests_total', 'Total API requests', ['endpoint', 'method'])
request_duration = Histogram('api_request_duration_seconds', 'Request duration', ['endpoint'])

# Add to FastAPI
metrics_app = make_asgi_app()
app.mount("/metrics", metrics_app)
```

Access metrics at: `http://localhost:8000/metrics`

### Grafana Dashboard

**Sample queries**:
- Request rate: `rate(api_requests_total[5m])`
- Average latency: `avg(api_request_duration_seconds)`
- Error rate: `rate(api_errors_total[5m])`

---

## Troubleshooting

### Common Issues

#### 1. API Won't Start

**Error**: `Address already in use`

**Solution**:
```powershell
# Windows - Find process using port 8000
Get-Process -Id (Get-NetTCPConnection -LocalPort 8000).OwningProcess | Stop-Process -Force

# Linux/macOS
lsof -ti:8000 | xargs kill -9
```

**Error**: `ModuleNotFoundError: No module named 'fastapi'`

**Solution**:
```bash
pip install -r requirements.txt
```

#### 2. Model Loading Failures

**Error**: `FileNotFoundError: models/road_speed_model.pkl not found`

**Solution**:
- Verify model files exist: `ls models/*.pkl`
- Check `MODELS_DIR` environment variable
- Re-download or retrain models if missing

**Error**: `pickle.UnpicklingError: invalid load key`

**Solution**:
- Model file corrupted - redownload
- Python version mismatch - use Python 3.9 or 3.10
- Scikit-learn version mismatch - check requirements.txt

#### 3. Slow Response Times

**Symptoms**: Response time >1 second

**Diagnosis**:
```bash
# Check API logs
tail -f logs/api.log

# Monitor resource usage
top -p $(pgrep -f uvicorn)
```

**Solutions**:
- Increase workers: `--workers 8`
- Add more RAM (model caching)
- Use faster storage (SSD)
- Enable model preloading
- Implement caching for repeated requests

#### 4. High Memory Usage

**Symptoms**: Memory >2GB per worker

**Solutions**:
- Reduce number of workers
- Implement lazy model loading
- Use model quantization (reduce precision)
- Clear feature engineering cache periodically

#### 5. Prediction Errors

**Error**: `422 Unprocessable Entity - Field required`

**Solution**: Check request JSON matches endpoint schema exactly

**Error**: `500 Internal Server Error - Feature engineering failed`

**Solution**: 
- Check logs for specific feature error
- Verify input values within expected ranges
- Ensure no NaN or infinite values in inputs

---

## Security Best Practices

### 1. API Authentication (Recommended for Production)

Add API key authentication:

```python
from fastapi import Security, HTTPException
from fastapi.security import APIKeyHeader

API_KEY = "your-secret-api-key"
api_key_header = APIKeyHeader(name="X-API-Key")

async def verify_api_key(api_key: str = Security(api_key_header)):
    if api_key != API_KEY:
        raise HTTPException(status_code=403, detail="Invalid API key")
    return api_key

# Protect endpoints
@app.post("/predict/road-speed", dependencies=[Security(verify_api_key)])
async def predict_road_speed(...):
    ...
```

### 2. Rate Limiting

```python
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address

limiter = Limiter(key_func=get_remote_address, default_limits=["100/hour"])
app.state.limiter = limiter
app.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)
```

### 3. HTTPS/TLS

**Always use HTTPS in production**:
- Obtain SSL certificate (Let's Encrypt, commercial CA)
- Configure Nginx/Apache for SSL termination
- Redirect HTTP ‚Üí HTTPS

### 4. Input Validation

Already implemented via Pydantic:
- Type checking (float, int, str)
- Range validation (`ge=0` for non-negative values)
- Required fields enforced

### 5. CORS Configuration

```python
from fastapi.middleware.cors import CORSMiddleware

app.add_middleware(
    CORSMiddleware,
    allow_origins=["https://minewise.com"],  # Specific domains only
    allow_credentials=True,
    allow_methods=["POST", "GET"],
    allow_headers=["*"],
)
```

---

## Backup & Recovery

### Model Backups

```bash
# Backup models daily
tar -czf models_backup_$(date +%Y%m%d).tar.gz models/

# Restore from backup
tar -xzf models_backup_20251210.tar.gz
```

### Database Backups (if using)

If adding database for request logging:

```bash
# PostgreSQL
pg_dump -U minewise -d minewise_db > backup_$(date +%Y%m%d).sql

# MongoDB
mongodump --db minewise_logs --out backup_$(date +%Y%m%d)/
```

---

## Support & Maintenance

### Updating Models

1. Train new model
2. Save as `model_name_v2.pkl`
3. Update `MODELS_DIR` path or rename
4. Restart API: `systemctl restart minewise-api`
5. Verify with health check

### API Versioning

For breaking changes, implement versioning:

```python
@app.post("/v1/predict/road-speed")
async def predict_road_speed_v1(...):
    ...

@app.post("/v2/predict/road-speed")
async def predict_road_speed_v2(...):
    # New implementation
    ...
```

### Contact & Support

- **Documentation**: `docs/` directory
- **Issues**: GitHub Issues
- **Email**: support@minewise.com
- **Slack**: #minewise-ml-support

---

## Quick Reference

### Startup Commands

```bash
# Development
uvicorn src.api.main:app --reload --host 0.0.0.0 --port 8000

# Production (Linux)
gunicorn src.api.main:app --workers 4 --worker-class uvicorn.workers.UvicornWorker --bind 0.0.0.0:8000

# Production (Windows)
uvicorn src.api.main:app --host 0.0.0.0 --port 8000 --workers 4

# Docker
docker run -d -p 8000:8000 minewise-api

# Test
python test_complete_validation.py
```

### Key URLs

- **API Base**: http://localhost:8000
- **Swagger Docs**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc
- **Health**: http://localhost:8000/health
- **Metrics**: http://localhost:8000/metrics (if Prometheus enabled)

### Environment Variables

```env
API_HOST=0.0.0.0
API_PORT=8000
API_WORKERS=4
MODELS_DIR=models
LOG_LEVEL=INFO
```

---

**Document Version**: 1.0  
**Last Updated**: December 10, 2025  
**Status**: Production Ready ‚úÖ  
**Deployment**: Tested on Windows, Linux, Docker

**üöÄ Ready to deploy MineWise ML API!**
